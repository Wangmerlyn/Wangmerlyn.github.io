<!doctype html><html class="not-ready text-sm lg:text-base" lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Nccl Allreduce -</title><meta name=theme-color><meta name=description content="起因 这篇文章的起因在于阅读OSDI'20的文章A Unified Architecture for Accelerating Distributed DNN Training in Heterogeneous GPU/CPU Clusters产生的疑问，文中作者举了如图所示的例子说明CPU和PCIe switch间的通信负载也会成为通信瓶颈，并如图计算了nccl的all-reduce算法在如下情况的瓶颈负载。 这让我好奇nccl all-reduce的计算原理是什么，以及如图所示的计算公式是怎么来的。
Github Issue 根据Github Issue中所言，nccl其实拥有3种不同的程序流程
ncclAllReduce ncclReduceScatter + ncclAllGather ncclReduce + ncclBroadcast 但是问题在于
第1种方法是否和第2种方法等价，如果不一样，那么ncclAllReduce究竟使用的是什么方法？ 第3种方法是不是像GPU参数服务器一样工作？ 第1问 两者是不一样的。
首先ncclAllReduce会基于buffer size内在地在2和3两种方法之间切换。 其次当ncclAllReduce方法使用&#34;reduce scatter plus allgather&#34;算法策略的时候，从实现的角度讲依然适合使用ncclReduceScatter()和ncclAllGather是不一样的。
第2问 两者是有稍微区别的。前者算法是树状实现的，如果树的高度只有1的话，那么就很像是参数服务器的样子了。
Issue总结 其实也就是说，当我们在使用ncclAllReduce的时候，其实涉及到了前面两种方法的切换和选择，其中前者更相似于Ring的结构，后者更类似于Tree的结构。
Nvidia 文档 其实在Nccl allreduce && BytePS原理这篇博客中，记录了NCCL关于集合通信的文档，在这里可以找到NCCL中all-reduce的实现算法。
在这之前，其实要先对一些通信原语进行解释 注：gather和reduce的区别在于，gather操作只是把数据不同的部分拼装在一起，而reduce是将位于不同机器上的同样类型的数据进行整合，前缀all的意义在于操作最终数据是在单独的机器上还是所有机器上。all-to-all则是从每个参与者到每个其它的参与者的直接scatter和gather。
Ring-Based Collectives 在最初步的Ring-Based解决方法中，我们可以发现，是流水线式的从GPU0到GPU1，在下一步中由GPU1到GPU2，如此进行。如何利用流水线之间的每个流程之间的可并行性是优化的一个思路。 通过将待广播的数据分为$S$份，这样在每一份数据进行转发的时候，就可以充分利用其它服务器的等待时间和带宽进行之前的数据的转发。在通常的环境中，$ S $ 会取得等于 $k$。
如此我们其实可以很容易理解为什么传输负载的计算公式是$$2(N-1)K/N$$
其中每次每个单独的GPU进行数据传输会发送$K/N$的数据,进行scatter会发送$N-1$次，进行broadcast会进行$N-1$。就得到了计算公式。
我们其实可以发现，在这个过程中NCCL使用的还是Ring All-Reduce方法"><meta name=author content="wang merlyn"><link rel="preload stylesheet" as=style href=/Wangmerlyn.github.io/main.min.css><link rel=preload as=image href=Wangmerlyn.github.io/theme.%7B%7B%20if%20site.Params.monoDarkIcon%20%7D%7Dsvg%7B%7B%20else%20%7D%7Dpng%7B%7B%20end%20%7D%7D><link rel=preload as=image href="https://www.gravatar.com/avatar/4cb92498631c99b1dca3aaf0b8488462?s=160&d=identicon"><link rel=preload as=image href=Wangmerlyn.github.io/github.svg><link rel=preload as=image href=Wangmerlyn.github.io/rss.svg><link rel=icon href=Wangmerlyn.github.io/favicon.ico><link rel=apple-touch-icon href=Wangmerlyn.github.io/apple-touch-icon.png><meta name=generator content="Hugo 0.101.0"><meta property="og:title" content="Nccl Allreduce"><meta property="og:description" content="what the hell algorithmn is nccl using"><meta property="og:type" content="article"><meta property="og:url" content="Wangmerlyn.github.io/posts/nccl-allreduce/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-07-28T15:38:11+08:00"><meta property="article:modified_time" content="2022-07-28T15:38:11+08:00"><meta itemprop=name content="Nccl Allreduce"><meta itemprop=description content="what the hell algorithmn is nccl using"><meta itemprop=datePublished content="2022-07-28T15:38:11+08:00"><meta itemprop=dateModified content="2022-07-28T15:38:11+08:00"><meta itemprop=wordCount content="62"><meta itemprop=keywords content="distributed learning,AI-systems,all-reduce,nccl,Network,Topology,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Nccl Allreduce"><meta name=twitter:description content="what the hell algorithmn is nccl using"></head><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><body class="text-black duration-200 ease-out dark:text-white"><header class="mx-auto flex h-[5rem] max-w-3xl px-8 lg:justify-center"><div class="relative z-50 mr-auto flex items-center"><a class="-translate-x-[1px] -translate-y-0.5 text-3xl font-bold" href=Wangmerlyn.github.io></a>
<a class="btn-dark ml-6 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.svg)_left_center/cover_no-repeat] dark:invert dark:[background-position:right]"></a></div><a class="btn-menu relative z-50 -mr-8 flex h-[5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"></a>
<script>const metaTheme=document.querySelector('meta[name="theme-color"]'),htmlClass=document.documentElement.classList;setTimeout(()=>htmlClass.remove("not-ready"),10);const setDark=e=>{metaTheme.setAttribute("content",e?"#000":"#fbfbfb"),htmlClass[e?"add":"remove"]("dark"),localStorage.setItem("dark",e)},darkScheme=window.matchMedia("(prefers-color-scheme: dark)"),darkVal=localStorage.getItem("dark");setDark(darkVal?darkVal==="true":darkScheme.matches),darkScheme.addEventListener("change",e=>{setDark(e.matches)});const btnDark=document.querySelector(".btn-dark");btnDark.addEventListener("click",()=>{setDark(localStorage.getItem("dark")!=="true")});const btnMenu=document.querySelector(".btn-menu");btnMenu.addEventListener("click",()=>{htmlClass.toggle("open")})</script><div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"><nav class="mt-12 flex justify-center space-x-10 dark:invert lg:mt-0 lg:ml-12 lg:items-center lg:space-x-6"><a class="h-8 w-8 [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./github.svg) href=https://github.com/Wangmerlyn target=_blank></a>
<a class="h-8 w-8 [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./rss.svg) href=Wangmerlyn.github.io/index.xml target=_blank></a></nav></div></header><main class="prose prose-neutral relative mx-auto min-h-[calc(100%-10rem)] max-w-3xl px-8 pt-20 pb-32 dark:prose-invert"><article><header class=mb-20><h1 class="!my-0 pb-2.5">Nccl Allreduce</h1><div class="text-sm opacity-60"><time>Jul 28, 2022</time>
<span class=mx-1>&#183;</span>
<span>wang merlyn</span></div></header><section><h1 id=起因>起因</h1><p>这篇文章的起因在于阅读OSDI'20的文章<a href=https://www.usenix.org/system/files/osdi20-jiang.pdf>A Unified Architecture for Accelerating Distributed DNN Training in Heterogeneous GPU/CPU Clusters</a>产生的疑问，文中作者举了如图所示的例子说明CPU和PCIe switch间的通信负载也会成为通信瓶颈，并如图计算了nccl的all-reduce算法在如下情况的瓶颈负载。
<img src=/images/nccl-all-reduce.png alt=nccl>
这让我好奇nccl all-reduce的计算原理是什么，以及如图所示的计算公式是怎么来的。</p><h1 id=github-issue>Github Issue</h1><p>根据<a href=https://github.com/NVIDIA/nccl/issues/256>Github Issue</a>中所言，nccl其实拥有3种不同的程序流程</p><ol><li>ncclAllReduce</li><li>ncclReduceScatter + ncclAllGather</li><li>ncclReduce + ncclBroadcast</li></ol><p>但是问题在于</p><ul><li>第1种方法是否和第2种方法等价，如果不一样，那么ncclAllReduce究竟使用的是什么方法？</li><li>第3种方法是不是像GPU参数服务器一样工作？</li></ul><h2 id=第1问>第1问</h2><p>两者是不一样的。</p><p>首先ncclAllReduce会基于buffer size内在地在2和3两种方法之间切换。
其次当ncclAllReduce方法使用"reduce scatter plus allgather"算法策略的时候，从实现的角度讲依然适合使用ncclReduceScatter()和ncclAllGather是不一样的。</p><h2 id=第2问>第2问</h2><p>两者是有稍微区别的。前者算法是树状实现的，如果树的高度只有1的话，那么就很像是参数服务器的样子了。</p><h2 id=issue总结>Issue总结</h2><p>其实也就是说，当我们在使用ncclAllReduce的时候，其实涉及到了前面两种方法的切换和选择，其中前者更相似于Ring的结构，后者更类似于Tree的结构。</p><h1 id=nvidia-文档>Nvidia 文档</h1><p>其实在<a href=https://www.cnblogs.com/deepllz/p/11347960.html>Nccl allreduce && BytePS原理</a>这篇博客中，记录了<a href=https://images.nvidia.cn/events/sc15/pdfs/NCCL-Woolley.pdf>NCCL关于集合通信的文档</a>，在这里可以找到NCCL中all-reduce的实现算法。</p><p>在这之前，其实要先对一些通信原语进行解释
<img src=/images/NCCL-Woolley-06.png alt=通信原语></p><p>注：gather和reduce的区别在于，gather操作只是把数据不同的部分拼装在一起，而reduce是将位于不同机器上的同样类型的数据进行整合，前缀all的意义在于操作最终数据是在单独的机器上还是所有机器上。all-to-all则是从每个参与者到每个其它的参与者的直接scatter和gather。</p><h1 id=ring-based-collectives>Ring-Based Collectives</h1><p><img src=/images/NCCL-Woolley-24.png alt=Ring>
在最初步的Ring-Based解决方法中，我们可以发现，是流水线式的从GPU0到GPU1，在下一步中由GPU1到GPU2，如此进行。如何利用流水线之间的每个流程之间的可并行性是优化的一个思路。
<img src=/images/NCCL-Woolley-28.png alt="Split Ring">
<img src=/images/NCCL-Woolley-30.png alt="Split Ring">
通过将待广播的数据分为$S$份，这样在每一份数据进行转发的时候，就可以充分利用其它服务器的等待时间和带宽进行之前的数据的转发。在通常的环境中，$ S $ 会取得等于 $k$。</p><p><img src=/images/NCCL-Woolley-32.png alt=All-Reduce>
<img src=/images/NCCL-Woolley-33.png alt=All-Reduce></p><p>如此我们其实可以很容易理解为什么传输负载的计算公式是$$2(N-1)K/N$$</p><p>其中每次每个单独的GPU进行数据传输会发送$K/N$的数据,进行scatter会发送$N-1$次，进行broadcast会进行$N-1$。就得到了计算公式。</p><p>我们其实可以发现，在这个过程中NCCL使用的还是Ring All-Reduce方法</p></section><footer class="mt-12 flex flex-wrap"><a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=Wangmerlyn.github.io/tags/distributed-learning>distributed learning</a>
<a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=Wangmerlyn.github.io/tags/ai-systems>AI-systems</a>
<a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=Wangmerlyn.github.io/tags/all-reduce>all-reduce</a>
<a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=Wangmerlyn.github.io/tags/nccl>nccl</a>
<a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=Wangmerlyn.github.io/tags/network>Network</a>
<a class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]" href=Wangmerlyn.github.io/tags/topology>Topology</a></footer><nav class="mt-24 flex rounded-lg bg-black/[3%] text-lg dark:bg-white/[8%]"><a class="flex w-1/2 items-center p-6 pr-3 no-underline" href=Wangmerlyn.github.io/posts/what-is-bisection-bandwidth/><span class=mr-1.5>←</span><span>What Is Bisection Bandwidth</span></a>
<a class="ml-auto flex w-1/2 items-center justify-end p-6 pl-3 no-underline" href=Wangmerlyn.github.io/posts/fogbus-translation/><span>FogBus Translation</span><span class=ml-1.5>→</span></a></nav></article></main><div class=pb-2><script src=https://utteranc.es/client.js repo=wangmerlyn/wangmerlyn.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></div><footer class="opaco mx-auto flex h-[5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60"><div class=mr-auto>&copy; 2022
<a class=link href=Wangmerlyn.github.io></a></div><a class="link mx-6" href=https://gohugo.io/ rel=noopener target=_blank>Powered by Hugo️️</a>️
<a class=link href=https://github.com/nanxiaobei/hugo-paper rel=noopener target=_blank>▷ Paper 6</a></footer></body></html>