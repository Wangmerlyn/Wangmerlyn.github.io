<!doctype html><html lang=en><head><title>Nccl Allreduce ::</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="what the hell algorithmn is nccl using"><meta name=keywords content=","><meta name=robots content="noodp"><link rel=canonical href=freewsy.ml/posts/nccl-allreduce/><link rel=stylesheet href=freewsy.ml/assets/style.css><link rel=stylesheet href=assets/%25!s%28%3cnil%3e%29.css><link rel=apple-touch-icon href=freewsy.ml/img/apple-touch-icon-192x192.png><link rel="shortcut icon" href=freewsy.ml/img/favicon/orange.png><meta name=twitter:card content="summary"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="og:title" content="Nccl Allreduce"><meta property="og:description" content="what the hell algorithmn is nccl using"><meta property="og:url" content="freewsy.ml/posts/nccl-allreduce/"><meta property="og:site_name" content><meta property="og:image" content="freewsy.ml"><meta property="og:image:width" content="2048"><meta property="og:image:height" content="1024"><meta property="article:published_time" content="2022-07-28 15:38:11 +0800 +0800"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></head><body><div class="container headings--one-size"><header class=header><div class=header__inner><div class=header__logo><a href=freewsy.ml><div class=logo>Terminal</div></a></div></div></header><div class=content><div class=post><h1 class=post-title><a href=freewsy.ml/posts/nccl-allreduce/>Nccl Allreduce</a></h1><div class=post-meta><span class=post-date>2022-07-28</span>
<span class=post-author>:: wang merlyn</span></div><span class=post-tags>#<a href=freewsy.ml/tags/distributed-learning/>distributed learning</a>&nbsp;
#<a href=freewsy.ml/tags/ai-systems/>AI-systems</a>&nbsp;
#<a href=freewsy.ml/tags/all-reduce/>all-reduce</a>&nbsp;
#<a href=freewsy.ml/tags/nccl/>nccl</a>&nbsp;
#<a href=freewsy.ml/tags/network/>Network</a>&nbsp;
#<a href=freewsy.ml/tags/topology/>Topology</a>&nbsp;</span><div class=post-content><div><h1 id=起因>起因<a href=#起因 class=hanchor arialabel=Anchor>&#8983;</a></h1><p>这篇文章的起因在于阅读OSDI'20的文章<a href=https://www.usenix.org/system/files/osdi20-jiang.pdf>A Unified Architecture for Accelerating Distributed DNN Training in Heterogeneous GPU/CPU Clusters</a>产生的疑问，文中作者举了如图所示的例子说明CPU和PCIe switch间的通信负载也会成为通信瓶颈，并如图计算了nccl的all-reduce算法在如下情况的瓶颈负载。
<img src=/images/nccl-all-reduce.png alt=nccl>
这让我好奇nccl all-reduce的计算原理是什么，以及如图所示的计算公式是怎么来的。</p><h1 id=github-issue>Github Issue<a href=#github-issue class=hanchor arialabel=Anchor>&#8983;</a></h1><p>根据<a href=https://github.com/NVIDIA/nccl/issues/256>Github Issue</a>中所言，nccl其实拥有3种不同的程序流程</p><ol><li>ncclAllReduce</li><li>ncclReduceScatter + ncclAllGather</li><li>ncclReduce + ncclBroadcast</li></ol><p>但是问题在于</p><ul><li>第1种方法是否和第2种方法等价，如果不一样，那么ncclAllReduce究竟使用的是什么方法？</li><li>第3种方法是不是像GPU参数服务器一样工作？</li></ul><h2 id=第1问>第1问<a href=#第1问 class=hanchor arialabel=Anchor>&#8983;</a></h2><p>两者是不一样的。</p><p>首先ncclAllReduce会基于buffer size内在地在2和3两种方法之间切换。
其次当ncclAllReduce方法使用"reduce scatter plus allgather"算法策略的时候，从实现的角度讲依然适合使用ncclReduceScatter()和ncclAllGather是不一样的。</p><h2 id=第2问>第2问<a href=#第2问 class=hanchor arialabel=Anchor>&#8983;</a></h2><p>两者是有稍微区别的。前者算法是树状实现的，如果树的高度只有1的话，那么就很像是参数服务器的样子了。</p><h2 id=issue总结>Issue总结<a href=#issue总结 class=hanchor arialabel=Anchor>&#8983;</a></h2><p>其实也就是说，当我们在使用ncclAllReduce的时候，其实涉及到了前面两种方法的切换和选择，其中前者更相似于Ring的结构，后者更类似于Tree的结构。</p><h1 id=nvidia-文档>Nvidia 文档<a href=#nvidia-文档 class=hanchor arialabel=Anchor>&#8983;</a></h1><p>其实在<a href=https://www.cnblogs.com/deepllz/p/11347960.html>Nccl allreduce && BytePS原理</a>这篇博客中，记录了<a href=https://images.nvidia.cn/events/sc15/pdfs/NCCL-Woolley.pdf>NCCL关于集合通信的文档</a>，在这里可以找到NCCL中all-reduce的实现算法。</p><p>在这之前，其实要先对一些通信原语进行解释
<img src=/images/NCCL-Woolley-06.png alt=通信原语></p><p>注：gather和reduce的区别在于，gather操作只是把数据不同的部分拼装在一起，而reduce是将位于不同机器上的同样类型的数据进行整合，前缀all的意义在于操作最终数据是在单独的机器上还是所有机器上。all-to-all则是从每个参与者到每个其它的参与者的直接scatter和gather。</p><h1 id=ring-based-collectives>Ring-Based Collectives<a href=#ring-based-collectives class=hanchor arialabel=Anchor>&#8983;</a></h1><p><img src=/images/NCCL-Woolley-24.png alt=Ring>
在最初步的Ring-Based解决方法中，我们可以发现，是流水线式的从GPU0到GPU1，在下一步中由GPU1到GPU2，如此进行。如何利用流水线之间的每个流程之间的可并行性是优化的一个思路。
<img src=/images/NCCL-Woolley-28.png alt="Split Ring">
<img src=/images/NCCL-Woolley-30.png alt="Split Ring">
通过将待广播的数据分为$S$份，这样在每一份数据进行转发的时候，就可以充分利用其它服务器的等待时间和带宽进行之前的数据的转发。在通常的环境中，$ S $ 会取得等于 $k$。</p><p><img src=/images/NCCL-Woolley-32.png alt=All-Reduce>
<img src=/images/NCCL-Woolley-33.png alt=All-Reduce></p><p>如此我们其实可以很容易理解为什么传输负载的计算公式是$$2(N-1)K/N$$</p><p>其中每次每个单独的GPU进行数据传输会发送$K/N$的数据,进行scatter会发送$N-1$次，进行broadcast会进行$N-1$。就得到了计算公式。</p><p>我们其实可以发现，在这个过程中NCCL使用的还是Ring All-Reduce方法</p></div></div></div></div><footer class=footer><div class=footer__inner><div class=copyright><span>© 2022 Powered by <a href=http://gohugo.io>Hugo</a></span>
<span>:: Theme made by <a href=https://twitter.com/panr>panr</a></span></div></div></footer><script src=freewsy.ml/assets/main.js></script>
<script src=freewsy.ml/assets/prism.js></script></div></body></html>